{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jyonalee/Insider-Threat-and-Anomaly-Detection-from-User-Activities/blob/master/Anomaly_Detection_LSTM_Data_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "IN1DD_4ENdh3",
    "outputId": "7546edde-3f51-4058-93dc-b44ca2fddadd"
   },
   "outputs": [],
   "source": [
    "# install awscli to download the data\n",
    "!pip3 install awscli --upgrade --user\n",
    "\n",
    "# download data and save it on `data`\n",
    "!mkdir data\n",
    "!~/.local/bin/aws s3 sync --no-sign-request --region us-west-1 \"s3://cse-cic-ids2018/Processed Traffic Data for ML Algorithms/\" data/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkKNa_ymcmhP"
   },
   "source": [
    "# Anomaly Detection with LSTM in Network Traffic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKUEkeVGb2Iw"
   },
   "source": [
    "This project explores anomaly detection in network traffic with RNN-LSTM to train the model.\n",
    "\n",
    "The dataset can be obtained [here](https://www.unb.ca/cic/datasets/ids-2018.html)\n",
    "\n",
    "This is part of the capstone project for the Machine Learning Nano Degree from Udacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kTBtr-Ibisb"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Xgqhe0NXYdQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from lib.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "76_1DLJ5cjp5",
    "outputId": "04d6efa2-e8c6-4608-f8c5-66f7be708706"
   },
   "outputs": [],
   "source": [
    "# if saved dataframe file exists, load\n",
    "# if dataframe isn't saved, load raw csv file and save the dataframe\n",
    "exists = os.path.isfile('flowmeter_dataframe.pkl')\n",
    "if exists:\n",
    "    df = pd.read_pickle('flowmeter_dataframe.pkl')\n",
    "else:\n",
    "    # load data and do preliminary cleaning\n",
    "    directory = '/home/jlee/cse-cic-ids2018/Processed Traffic Data for ML Algorithms'\n",
    "\n",
    "    filepath = os.path.join(directory,'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df1 = pd.read_csv(filepath)\n",
    "    df1 = df1[df1['Protocol'] != 'Protocol']\n",
    "    df1 = optimize_and_clean_df(df1)\n",
    "\n",
    "    filepath = os.path.join(directory,'Friday-16-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df2 = pd.read_csv(filepath)\n",
    "    df2 = df2[df2['Protocol'] != 'Protocol']\n",
    "    df2 = optimize_and_clean_df(df2)\n",
    "\n",
    "    filepath = os.path.join(directory,'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df3 = pd.read_csv(filepath)\n",
    "    df3 = optimize_and_clean_df(df3)\n",
    "\n",
    "    filepath = os.path.join(directory,'Friday-23-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df4 = pd.read_csv(filepath)\n",
    "    df4 = optimize_and_clean_df(df4)\n",
    "\n",
    "    filepath = os.path.join(directory,'Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df5 = pd.read_csv(filepath)\n",
    "    df5 = optimize_and_clean_df(df5)\n",
    "\n",
    "    filepath = os.path.join(directory,'Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df6 = pd.read_csv(filepath)\n",
    "    df6 = optimize_and_clean_df(df6)\n",
    "\n",
    "    filepath = os.path.join(directory,'Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df7 = pd.read_csv(filepath)\n",
    "    df7 = optimize_and_clean_df(df7)\n",
    "\n",
    "    filepath = os.path.join(directory,'Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df8 = pd.read_csv(filepath)\n",
    "    df8 = df8[df8['Protocol'] != 'Protocol']\n",
    "    df8 = optimize_and_clean_df(df8)\n",
    "\n",
    "    filepath = os.path.join(directory,'Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    df9 = pd.read_csv(filepath)\n",
    "    df9 = optimize_and_clean_df(df9)\n",
    "    \n",
    "    # combine dataframes to one\n",
    "    df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9], ignore_index=True)\n",
    "    \n",
    "    # save dataframe to file for future use\n",
    "    pd.to_pickle(df, 'flowmeter_dataframe.pkl')\n",
    "    \n",
    "    # clean up intermediary dataframes to free memory\n",
    "    del df1\n",
    "    del df2\n",
    "    del df3\n",
    "    del df4\n",
    "    del df5\n",
    "    del df6\n",
    "    del df7\n",
    "    del df8\n",
    "    del df9\n",
    "    \n",
    "    ### this file is significantly larger (~4gb csv which crashes a 16gb machine with out of memory) so excluding for now\n",
    "    # filepath = os.path.join(directory,'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "    # df10 = pd.read_csv(filepath)\n",
    "    # df10 = df10[df10['Protocol'] != 'Protocol']\n",
    "    # df10 = optimize_and_clean_df(df10)\n",
    "\n",
    "    # df = pd.concat([df,df10], ignore_index=True)\n",
    "    # del df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2338.5255813598633"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage().sum() / 1024**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8284195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Timestamp'] > pd.to_datetime('2018-01-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign                      6112137\n",
      "DDOS attack-HOIC             686012\n",
      "DoS attacks-Hulk             461912\n",
      "Bot                          286191\n",
      "FTP-BruteForce               193360\n",
      "SSH-Bruteforce               187589\n",
      "Infilteration                161934\n",
      "DoS attacks-SlowHTTPTest     139890\n",
      "DoS attacks-GoldenEye         41508\n",
      "DoS attacks-Slowloris         10990\n",
      "DDOS attack-LOIC-UDP           1730\n",
      "Brute Force -Web                611\n",
      "Brute Force -XSS                230\n",
      "SQL Injection                    87\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get count of each label\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign                      0.737808\n",
      "DDOS attack-HOIC            0.082810\n",
      "DoS attacks-Hulk            0.055758\n",
      "Bot                         0.034547\n",
      "FTP-BruteForce              0.023341\n",
      "SSH-Bruteforce              0.022644\n",
      "Infilteration               0.019547\n",
      "DoS attacks-SlowHTTPTest    0.016886\n",
      "DoS attacks-GoldenEye       0.005011\n",
      "DoS attacks-Slowloris       0.001327\n",
      "DDOS attack-LOIC-UDP        0.000209\n",
      "Brute Force -Web            0.000074\n",
      "Brute Force -XSS            0.000028\n",
      "SQL Injection               0.000011\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# get distribution in of each label\n",
    "print(df['Label'].value_counts()/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in essence, 73.8% of data points in this dataset is 'Benign' while the rest are some form of malicious attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3389</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-02-14 01:00:00</td>\n",
       "      <td>1671932</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1144</td>\n",
       "      <td>1581</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3389</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-02-14 01:00:00</td>\n",
       "      <td>3641507</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1148</td>\n",
       "      <td>1581</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-02-14 01:00:00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3389</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-02-14 01:00:00</td>\n",
       "      <td>4363661</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1148</td>\n",
       "      <td>1581</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3389</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-02-14 01:00:00</td>\n",
       "      <td>1297112</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1138</td>\n",
       "      <td>1581</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dst Port Protocol           Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
       "0     3389        6 2018-02-14 01:00:00        1671932             8   \n",
       "1     3389        6 2018-02-14 01:00:00        3641507             8   \n",
       "2       80        6 2018-02-14 01:00:00             89             2   \n",
       "3     3389        6 2018-02-14 01:00:00        4363661             8   \n",
       "4     3389        6 2018-02-14 01:00:00        1297112             8   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "0             7             1144             1581              677   \n",
       "1            10             1148             1581              677   \n",
       "2             0                0                0                0   \n",
       "3            11             1148             1581              677   \n",
       "4             7             1138             1581              677   \n",
       "\n",
       "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                0  ...                20          0.0         0.0   \n",
       "1                0  ...                20          0.0         0.0   \n",
       "2                0  ...                20          0.0         0.0   \n",
       "3                0  ...                20          0.0         0.0   \n",
       "4                0  ...                20          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
       "0           0           0        0.0       0.0         0         0  Benign  \n",
       "1           0           0        0.0       0.0         0         0  Benign  \n",
       "2           0           0        0.0       0.0         0         0  Benign  \n",
       "3           0           0        0.0       0.0         0         0  Benign  \n",
       "4           0           0        0.0       0.0         0         0  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo:\n",
    "# more stats\n",
    "# plot timeline of events\n",
    "# determine what is a normal sequence vs not normal sequence and visualize if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo:\n",
    "# with the definition of a `normal sequence`, need to transform & process the data accordingly before training with LSTM\n",
    "# with the baseline algorithms for anomaly detection, should be fine to train with given data as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Anomaly_Detection_LSTM_Data_Exploration.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
